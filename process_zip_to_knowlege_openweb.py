# -*- coding: utf-8 -*-
"""process_zip_to_knowlege_openweb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ccxh6W7dTPj0ayOMdoxOdkCcUk4kHenT
"""

import os
import zipfile
import uuid
import requests
import json
import shutil
from pathlib import Path

# Configuration
DEEPSEEK_API_KEY = "sk-7fd014d945684bf5b00c27c092d8866c"
OPENWEBUI_API_KEY = "sk-2406b6ef10774af08dfb0a12d235cb98"
DEEPSEEK_URL = "https://api.deepseek.com/v1"  # Updated DeepSeek API endpoint
OPENWEBUI_URL = "https://sendthemmoney.com"
KNOWLEDGE_COLLECTION_ID = "721971bb-5ad1-4176-b79b-f2900564abc5"
TEMP_DIR = "temp_unzipped"
CLEANED_DIR = "/content/cleaned_files"
QNA_FILE = "/content/qna_dataset.json"

PROCESSING_PROMPT = """Please process this document by:
1. Removing any irrelevant content or formatting artifacts
2. Organizing the structure logically
3. Identifying the main topic/subject
4. Suggesting a filename based on the main topic using lowercase_with_underscores format

Return JSON format with:
{
  "cleaned_content": "processed markdown content",
  "topic": "main topic name",
  "suggested_filename": "topic_based_name.md"
}"""

def unzip_and_rename(zip_path):
    """Unzips Firecrawl output while preserving original filenames"""
    os.makedirs(TEMP_DIR, exist_ok=True)

    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(TEMP_DIR)

    return os.listdir(TEMP_DIR)

def process_with_deepseek(file_path):
    """Process file with DeepSeek API for cleaning and topic extraction"""
    with open(file_path, 'r', encoding='utf-8') as f:
        raw_content = f.read()

    response = requests.post(
        f"{DEEPSEEK_URL}/chat/completions",
        headers={
            "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
            "Content-Type": "application/json"
        },
        json={
            "model": "deepseek-chat",
            "messages": [
                {"role": "system", "content": "You are a helpful assistant that processes documents and extracts structured information."},
                {"role": "user", "content": f"{PROCESSING_PROMPT}\n\n{raw_content}"}
            ],
            "response_format": {"type": "json_object"},
            "temperature": 0.3
        }
    )

    if response.status_code != 200:
        raise Exception(f"DeepSeek processing failed: {response.status_code} - {response.text}")

    try:
        result = json.loads(response.json()['choices'][0]['message']['content'])
        cleaned_content = result['cleaned_content']
        topic = result['topic']
        base_name = result['suggested_filename'].replace('.md', '')[:50]  # Limit filename length
    except (KeyError, json.JSONDecodeError) as e:
        raise Exception(f"Failed to parse DeepSeek response: {str(e)}")

    # Generate safe filename
    final_filename = f"{base_name}_{uuid.uuid4().hex[:4]}.md"
    cleaned_path = Path(CLEANED_DIR) / final_filename

    os.makedirs(CLEANED_DIR, exist_ok=True)
    with open(cleaned_path, 'w', encoding='utf-8') as f:
        f.write(cleaned_content)

    return cleaned_path, topic

def upload_to_openwebui(file_path):
    """Uploads cleaned file to OpenWebUI"""
    with open(file_path, 'rb') as f:
        response = requests.post(
            f"{OPENWEBUI_URL}/api/v1/files/",
            headers={"Authorization": f"Bearer {OPENWEBUI_API_KEY}"},
            files={"file": f}
        )

    if response.status_code == 200:
        return response.json()['id']
    raise Exception(f"OpenWebUI upload failed: {response.status_code} - {response.text}")

def add_to_collection(file_id):
    """Adds file to knowledge collection in OpenWebUI"""
    response = requests.post(
        f"{OPENWEBUI_URL}/api/v1/knowledge/{KNOWLEDGE_COLLECTION_ID}/file/add",
        headers={
            "Authorization": f"Bearer {OPENWEBUI_API_KEY}",
            "Content-Type": "application/json"
        },
        json={"file_id": file_id}
    )
    return response.status_code == 200

def generate_qna():
    """Generates Q&A using OpenWebUI's knowledge collection"""
    response = requests.post(
        f"{OPENWEBUI_URL}/api/chat/completions",
        headers={
            "Authorization": f"Bearer {OPENWEBUI_API_KEY}",
            "Content-Type": "application/json"
        },
        json={
            "model": "deepseek-chat",
            "messages": [{
                "role": "user",
                "content": "Generate 50 diverse questions and answers based on the knowledge collection. Format as JSON: {qna: [{question, answer}]}"
            }],
            "files": [{
                "type": "collection",
                "id": KNOWLEDGE_COLLECTION_ID
            }]
        }
    )

    if response.status_code == 200:
        return response.json()['choices'][0]['message']['content']
    raise Exception(f"QNA generation failed: {response.status_code} - {response.text}")

def main(zip_path):
    # Process files
    files = unzip_and_rename(zip_path)
    file_ids = []
    topics = set()

    for file in files:
        try:
            temp_path = Path(TEMP_DIR) / file
            cleaned_path, topic = process_with_deepseek(temp_path)

            file_id = upload_to_openwebui(cleaned_path)
            if add_to_collection(file_id):
                file_ids.append(file_id)
                topics.add(topic)
            print(f"Processed and uploaded: {file} -> {topic}")
        except Exception as e:
            print(f"Error processing {file}: {str(e)}")

    # Generate Q&A dataset
    try:
        qna_raw = generate_qna()
        qna_data = json.loads(qna_raw)
        with open(QNA_FILE, 'w') as f:
            json.dump(qna_data, f, indent=2)
        print(f"Generated {len(qna_data.get('qna', []))} Q&A pairs")
    except Exception as e:
        print(f"Failed to generate Q&A: {str(e)}")

    # Cleanup
    shutil.rmtree(TEMP_DIR, ignore_errors=True)
    shutil.rmtree(CLEANED_DIR, ignore_errors=True)

if __name__ == "__main__":
    firecrawl_zip = "/content/markdown_results(2).zip"
    main(firecrawl_zip)

import os
import zipfile
import uuid
import requests
import json
import shutil
import re
import subprocess
from pathlib import Path

# Configuration
DEEPSEEK_API_KEY = "-7fd014d945684bf5b00c27c092d8866c"
OPENWEBUI_API_KEY = "-2406b6ef10774af08dfb0a12d235cb98"
DEEPSEEK_URL = "https://api.deepseek.com/v1"  # Updated DeepSeek API endpoint
OPENWEBUI_URL = "https://sendthemmoney.com"
KNOWLEDGE_COLLECTION_ID = "721971bb-5ad1-4176-b79b-f2900564abc5"
EXTRACT_DIR = "/content/markdown"  # Directory for extracted files
CLEANED_DIR = "/content/cleaned_files"  # Directory for cleaned files
QNA_FILE = "/content/qna_dataset.json"

PROCESSING_PROMPT = """Please process this document by:
1. Removing any irrelevant content or formatting artifacts
2. Organizing the structure logically
3. Identifying the main topic/subject
4. Suggesting a filename based on the main topic using lowercase_with_underscores format

Return JSON format with:
{
  "cleaned_content": "processed markdown content",
  "topic": "main topic name",
  "suggested_filename": "topic_based_name.md"
}"""

def extract_and_clean_filenames(zip_path, extract_dir):
    """Extracts the zip file and cleans up filenames"""
    # Extract the zip file
    subprocess.run(["unzip", zip_path, "-d", extract_dir])

    # Clean up the file names
    for filename in os.listdir(extract_dir):
        if filename.endswith(".md"):  # Process only markdown files
            old_path = os.path.join(extract_dir, filename)

            # Remove the leading part of the path, leaving only the last few components
            new_filename = re.sub(r'^www_canva_dev_docs_', '', filename)

            # Remove any additional leading or trailing underscores
            new_filename = new_filename.strip('_')

            # Replace underscores with dashes to make file names more readable
            new_filename = new_filename.replace('_', '-')

            new_path = os.path.join(extract_dir, new_filename)

            # Rename the file
            os.rename(old_path, new_path)

    print("Extraction and filename cleanup complete.")
    return os.listdir(extract_dir)

def process_with_deepseek(file_path):
    """Process file with DeepSeek API for cleaning and topic extraction"""
    with open(file_path, 'r', encoding='utf-8') as f:
        raw_content = f.read()

    response = requests.post(
        f"{DEEPSEEK_URL}/chat/completions",
        headers={
            "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
            "Content-Type": "application/json"
        },
        json={
            "model": "deepseek-chat",
            "messages": [
                {"role": "system", "content": "You are a helpful assistant that processes documents and extracts structured information."},
                {"role": "user", "content": f"{PROCESSING_PROMPT}\n\n{raw_content}"}
            ],
            "response_format": {"type": "json_object"},
            "temperature": 0.3
        }
    )

    if response.status_code != 200:
        raise Exception(f"DeepSeek processing failed: {response.status_code} - {response.text}")

    try:
        result = json.loads(response.json()['choices'][0]['message']['content'])
        cleaned_content = result['cleaned_content']
        topic = result['topic']
        base_name = result['suggested_filename'].replace('.md', '')[:50]  # Limit filename length
    except (KeyError, json.JSONDecodeError) as e:
        raise Exception(f"Failed to parse DeepSeek response: {str(e)}")

    # Generate safe filename
    final_filename = f"{base_name}_{uuid.uuid4().hex[:4]}.md"
    cleaned_path = Path(CLEANED_DIR) / final_filename

    os.makedirs(CLEANED_DIR, exist_ok=True)
    with open(cleaned_path, 'w', encoding='utf-8') as f:
        f.write(cleaned_content)

    return cleaned_path, topic

def upload_to_openwebui(file_path):
    """Uploads cleaned file to OpenWebUI"""
    with open(file_path, 'rb') as f:
        response = requests.post(
            f"{OPENWEBUI_URL}/api/v1/files/",
            headers={"Authorization": f"Bearer {OPENWEBUI_API_KEY}"},
            files={"file": f}
        )

    if response.status_code == 200:
        return response.json()['id']
    raise Exception(f"OpenWebUI upload failed: {response.status_code} - {response.text}")

def add_to_collection(file_id):
    """Adds file to knowledge collection in OpenWebUI"""
    response = requests.post(
        f"{OPENWEBUI_URL}/api/v1/knowledge/{KNOWLEDGE_COLLECTION_ID}/file/add",
        headers={
            "Authorization": f"Bearer {OPENWEBUI_API_KEY}",
            "Content-Type": "application/json"
        },
        json={"file_id": file_id}
    )
    return response.status_code == 200

def generate_qna():
    """Generates Q&A using OpenWebUI's knowledge collection"""
    response = requests.post(
        f"{OPENWEBUI_URL}/api/chat/completions",
        headers={
            "Authorization": f"Bearer {OPENWEBUI_API_KEY}",
            "Content-Type": "application/json"
        },
        json={
            "model": "deepseek-chat",
            "messages": [{
                "role": "user",
                "content": "Generate 50 diverse questions and answers based on the knowledge collection. Format as JSON: {qna: [{question, answer}]}"
            }],
            "files": [{
                "type": "collection",
                "id": KNOWLEDGE_COLLECTION_ID
            }]
        }
    )

    if response.status_code == 200:
        return response.json()['choices'][0]['message']['content']
    raise Exception(f"QNA generation failed: {response.status_code} - {response.text}")

def main(zip_path):
    # Extract and clean filenames
    files = extract_and_clean_filenames(zip_path, EXTRACT_DIR)
    file_ids = []
    topics = set()

    # Process each file
    for file in files:
        try:
            file_path = Path(EXTRACT_DIR) / file
            cleaned_path, topic = process_with_deepseek(file_path)

            file_id = upload_to_openwebui(cleaned_path)
            if add_to_collection(file_id):
                file_ids.append(file_id)
                topics.add(topic)
            print(f"Processed and uploaded: {file} -> {topic}")
        except Exception as e:
            print(f"Error processing {file}: {str(e)}")

    # Generate Q&A dataset
    try:
        qna_raw = generate_qna()
        qna_data = json.loads(qna_raw)
        with open(QNA_FILE, 'w') as f:
            json.dump(qna_data, f, indent=2)
        print(f"Generated {len(qna_data.get('qna', []))} Q&A pairs")
    except Exception as e:
        print(f"Failed to generate Q&A: {str(e)}")

    # Cleanup
    shutil.rmtree(EXTRACT_DIR, ignore_errors=True)
    shutil.rmtree(CLEANED_DIR, ignore_errors=True)

if __name__ == "__main__":
    firecrawl_zip = "/content/markdown_results(2)(1).zip"
    main(firecrawl_zip)